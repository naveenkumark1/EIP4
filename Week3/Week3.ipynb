{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenkumark1/EIP4/blob/master/Week3/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-D70uI-8x3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,SeparableConv2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout,GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax926oiu9zJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQAQyM7D92eD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(train_labels[:]==i)[0]\n",
        "    features_idx = train_features[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(class_names[i])\n",
        "    plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZyP9Kb92m-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvXFC6AP92s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BILgyEwa92vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OfKWKc892yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Model Building - BASE(Rohan) acc- 82.98 Best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-HE7lxi921G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "# Rohan's model Base\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(48, 3, 3, border_mode='same', input_shape=(32, 32, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(48, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(96, 3, 3, border_mode='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(96, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(192, 3, 3, border_mode='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(192, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he0bfPnn923r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl7_-vhD926W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 50, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1)\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu08UZSY929K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our best Model - acc = 82.98"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af0_yT0u92_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Defineing New Model\n",
        "# Final Model\n",
        "weight_decay = 1e-4 ## https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/\n",
        "model1 = Sequential()\n",
        "model1.add(SeparableConv2D(filters= 32,kernel_size=(3,3),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,input_shape=(32,32,3),activation='relu'))  #30\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "# 30*30*32\n",
        "#receptive field =3\n",
        "model1.add(SeparableConv2D(filters= 64,kernel_size=(3,3),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) #28\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(BatchNormalization())\n",
        "# 28*28*64\n",
        "#receptive field =5\n",
        "model1.add(SeparableConv2D(filters= 128,kernel_size=(3,3),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) #26\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "# 26*26*128\n",
        "#receptive field =7\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2))) #13\n",
        "# 13*13*32\n",
        "#receptive field =8\n",
        "\n",
        "model1.add(SeparableConv2D(filters= 128,kernel_size=(3,3),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) #11\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# 11*11*128\n",
        "#receptive field =12\n",
        "\n",
        "model1.add(SeparableConv2D(filters= 256,kernel_size=(3,3),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) #9\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# 9*9*256\n",
        "#receptive field =16\n",
        "\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "\n",
        "# 4*4*256\n",
        "#receptive field =18\n",
        "\n",
        "model1.add(SeparableConv2D(filters= 64,kernel_size=(1,1),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# 4*4*64\n",
        "#receptive field =18\n",
        "\n",
        "model1.add(SeparableConv2D(filters= 10,kernel_size=(1,1),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# 4*4*10\n",
        "#receptive field =18\n",
        "model1.add(SeparableConv2D(filters= 10,kernel_size=(4,4),kernel_regularizer=regularizers.l2(weight_decay),depth_multiplier = 1,activation='relu')) \n",
        "\n",
        "# 1*1*10\n",
        "#receptive field =30\n",
        "model1.add(GlobalAveragePooling2D())\n",
        "model1.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRIKpene-PbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.005 * 1/(1 + 0.319 * epoch), 20)\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.005), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plW30OrH-Pd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_SePuR-Pgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Final Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(zoom_range=0.0,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model1_info = model1.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 50, \n",
        "                                 validation_data = (test_features, test_labels), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model1_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vV1oxyo-PjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHSDPp88-Plk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhwVHglg-PoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdAkfCjp-Pqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}